import time
from abc import abstractmethod
from dataclasses import dataclass, field
from math import ceil
from multiprocessing import Event, Process, Value
from pathlib import Path

import numpy as np
from ome_types.model import OME, Channel, Image, Pixels, Pixels_DimensionOrder, PixelType, UnitsLength
from voxel.utils.log import VoxelLogging
from voxel.utils.shared_double_buffer import SharedDoubleBuffer
from voxel.utils.vec import Vec2D, Vec3D


@dataclass
class WriterConfig:
    """Configuration properties for a frame stack writer."""

    path: str | Path
    frame_count: int
    frame_shape: Vec2D[int]
    position_um: Vec3D[float]
    file_name: str
    channel_name: str
    batch_size: int
    channel_idx: int = 0
    voxel_size: Vec3D[float] = field(default_factory=lambda: Vec3D(1.0, 1.0, 1.0))

    def to_dict(self) -> dict:
        return {
            "path": str(self.path),
            "frame_count": self.frame_count,
            "frame_shape": self.frame_shape.to_str(),
            "position_um": self.position_um.to_str(),
            "file_name": self.file_name,
            "channel_name": self.channel_name,
            "channel_idx": self.channel_idx,
            "voxel_size": self.voxel_size.to_str(),
        }


class VoxelWriter:
    """Writer class for voxel data with double buffering."""

    def __init__(self, name: str) -> None:
        """Initialize the writer.

        :param name: Name of the writer instance
        :type name: str
        """
        self.name = name
        self.log = VoxelLogging.get_logger(obj=self)
        self._log_queue = VoxelLogging.get_queue()

        self.dimension_order = Pixels_DimensionOrder.XYZCT
        self.voxel_size_unit = UnitsLength.MICROMETER

        self.timeout = 5  # TODO - Utilize this timeout
        self.config: WriterConfig
        self.ome: OME
        self._ome_xml: str

        self._dbl_buf: SharedDoubleBuffer
        self._proc: Process

        # Synchronization primitives
        self._is_running = Event()
        self._needs_processing = Event()

        self._frame_shape: Vec2D
        self._frames_added = Value("i", 0)
        self._frames_processed = Value("i", 0)
        self._batch_count = Value("i", 0)
        self._avg_rate = Value("d", 0.0)
        self._avg_fps = Value("d", 0.0)

        self._expected_batches = 0
        self._total_data_written = 0
        self._start_time = 0
        self._end_time = 0

    @property
    def dtype(self) -> str:
        """Data type for the written data."""
        return self.pixel_type.numpy_dtype

    @property
    def axes(self) -> str:
        return "".join([axis for axis in self.dimension_order.value if axis in "ZCYX"])[::-1]

    @property
    def is_running(self) -> bool:
        return self._is_running.is_set()

    @property
    def batch_count(self) -> int:
        return self._batch_count.value

    @property
    def frames_added(self) -> int:
        return self._frames_added.value

    @property
    def frames_processed(self) -> int:
        return self._frames_processed.value

    @property
    def avg_write_speed_mb_s(self) -> float:
        return self._avg_rate.value

    @property
    def avg_write_speed_fps(self) -> float:
        return self._avg_fps.value

    @property
    @abstractmethod
    def batch_size_px(self) -> int:
        """The number of pixels in the z dimension per batch. Determines the size of the buffer.

        :return: Size of batch in Z dimension
        :rtype: int
        """

    @property
    @abstractmethod
    def pixel_type(self) -> PixelType:
        """Pixel type for the written data.

        :return: Pixel type
        :rtype: PixelType
        """

    @abstractmethod
    def _initialize(self) -> None:
        """Initialize the writer. Called in subprocess after spawning."""

    @abstractmethod
    def _process_batch(self, batch_data: np.ndarray) -> None:
        """Process a batch of data with validation and metrics.

        :param batch_data: The batch of frame data to process
        :type batch_data: np.ndarray
        """

    @abstractmethod
    def _finalize(self) -> None:
        """Finalize the writer. Called before joining the writer subprocess."""

    @abstractmethod
    def configure(self, config: WriterConfig) -> None:
        """Configure the writer with the given properties.
        Ensure that self._props is assigned in this method.
        :param props: Configuration properties
        :type props: WriterProps.
        """
        self.config = config
        self.dir = Path(self.config.path)
        if not self.dir.exists():
            self.dir.mkdir(parents=True, exist_ok=True)
            self.log.warning("Directory %s did not exist. Created it.", self.dir)
        self.log.info("Configured writer with output directory: %s", self.dir)

        self._expected_batches = ceil(self.config.frame_count / self.batch_size_px)

        if hasattr(self, "_dbl_buf") and self._dbl_buf:
            self._dbl_buf.close_and_unlink()
            del self._dbl_buf
        batch_shape = (
            self.batch_size_px,
            self.config.frame_shape.y,
            self.config.frame_shape.x,
        )
        self._dbl_buf = SharedDoubleBuffer(batch_shape, self.dtype)
        self.log.info("Allocated buffer with shape: %s", self._dbl_buf.shape)
        self.log.info("Expecting: %d batches of <= %d frames", self._expected_batches, self.batch_size_px)
        try:
            self._proc = Process(name=self.name, target=self._run)
        except Exception as e:
            if self._dbl_buf:
                self._dbl_buf.close_and_unlink()
            msg = f"Failed to configure writer: {e}"
            raise RuntimeError(msg) from e

    def start(self) -> None:
        """Start the writer with the given configuration.

        :param props: Configuration properties
        :type props: WriterProps
        :raises RuntimeError: If writer fails to start
        """
        if not self.config:
            raise RuntimeError("Writer properties not set. Call configure() before starting the writer.")
        if not self._dbl_buf:
            self.log.critical("Unable to start writer. Buffer not allocated.")
        try:
            self.ome = self._generate_ome_metadata()
            self._ome_xml = self.ome.to_xml()
            self._is_running.set()
            self._needs_processing.clear()
            self._total_data_written = 0
            self._frames_added.value = 0
            self._frames_processed.value = 0
            self._batch_count.value = 0
            self._avg_rate.value = 0
            self._avg_fps.value = 0
            self._proc = Process(name=self.name, target=self._run)
            self._proc.start()
            self.log.debug("Writer started. Write buffer idx: %d", self._dbl_buf.write_mem_block_idx.value)
            self.log.debug("Start - Info: Added: %d, Processed: %d", self.frames_added, self.frames_processed)
        except Exception as e:
            msg = f"Failed to start writer: {e}"
            raise RuntimeError(msg) from e

    def add_frame(self, frame: np.ndarray) -> None:
        """Add a frame to the writer.

        :param frame: Frame data to add
        :type frame: np.ndarray
        """
        if not self._dbl_buf:
            raise RuntimeError("Buffer not allocated. Call configure() before starting and adding frames to writer.")

        if not self._is_running.is_set():
            raise RuntimeError("Writer not running. Call start() before adding frames.")

        self._dbl_buf.add_frame(frame)
        self._frames_added.value += 1
        # self.log.debug(f"Added frame {self.frames_added} to buffer")

        is_last_frame = self.frames_added == self.config.frame_count
        buffer_full = self.frames_added > 0 and self.frames_added % self._dbl_buf.shape[0] == 0

        if buffer_full or is_last_frame:
            self._switch_buffers()

        if is_last_frame:
            self.log.info("Added last frame %d to buffer. Waiting for processing to complete...", self.frames_added)
            while self.frames_added > self.frames_processed:
                time.sleep(0.1)

    def _switch_buffers(self) -> None:
        """Switch read and write buffers with proper synchronization."""
        if not self._dbl_buf:
            raise RuntimeError("Buffer not allocated. Call configure() before starting and adding frames to writer.")

        # Wait for any ongoing processing to complete
        while self._needs_processing.is_set():
            time.sleep(0.001)

        # Toggle buffers
        self._dbl_buf.toggle_buffers()
        self.log.debug("Switched buffers. Write buffer: %d", self._dbl_buf.write_mem_block_idx.value)

        # Signal that new data needs processing
        self._needs_processing.set()

        # Wait for processing to start before continuing
        while not self._needs_processing.is_set():
            self.log.debug("Waiting for processing to start on batch %d", self.batch_count)
            time.sleep(0.001)

    def _run(self) -> None:
        """Main writer loop."""
        # from voxel.utils.log import VoxelLogging

        VoxelLogging.redirect([self.log], self._log_queue)

        self._initialize()

        while self._is_running.is_set():
            if not self._dbl_buf:
                self.log.error("Buffer not allocated. Exiting writer loop.")
                break
            if self._needs_processing.is_set():
                mem_block = self._dbl_buf.mem_blocks[self._dbl_buf.read_mem_block_idx.value]
                shape = (self._dbl_buf.num_frames.value, *self._dbl_buf.shape[1:])
                batch_data: np.ndarray = np.ndarray(shape, dtype=self.dtype, buffer=mem_block.buf)

                self._timed_batch_processing(batch_data)

                self._needs_processing.clear()
                self._dbl_buf.num_frames.value = 0

            else:
                time.sleep(0.1)

        self._finalize()

    def _timed_batch_processing(self, batch_data: np.ndarray) -> None:
        """Process a batch of data with timing information.

        :param batch_data: The batch of frame data to process
        :type batch_data: np.ndarray
        :param batch_count: Current batch number (1-based)
        :type batch_count: int
        """
        try:
            batch_start_time = time.time()
            self._process_batch(batch_data)
            batch_end_time = time.time()

            self._batch_count.value += 1
            self._frames_processed.value += batch_data.shape[0]

            time_taken = batch_end_time - batch_start_time
            data_size_mb_s = batch_data.nbytes / (1024 * 1024)
            rate_mbps = data_size_mb_s / time_taken if time_taken > 0 else 0
            rate_fps = batch_data.shape[0] / time_taken
            self._avg_rate.value = (self._avg_rate.value * (self.batch_count - 1) + rate_mbps) / (self.batch_count or 1)
            self._avg_fps.value = (self._avg_fps.value * (self.batch_count - 1) + rate_fps) / (self.batch_count or 1)

            self.log.info(
                "Batch %d/%d Complete, Frames: %d",
                self.batch_count,
                self._expected_batches,
                batch_data.shape[0],
            )
            self.log.info("\tTime: %.2f s, Size: %.2f MB", time_taken, data_size_mb_s)
            self.log.info("\tRate: %.2f MB/s | %.2f fps", rate_mbps, rate_fps)
            self.log.info("\tAvg Rate: %.2f MB/s | %.2f fps", self.avg_write_speed_mb_s, self.avg_write_speed_fps)
        except Exception:
            self.log.exception("Error processing batch")

    def stop(self) -> None:
        """Stop the writer and clean up resources."""
        while self._needs_processing.is_set() or self.frames_added > self.frames_processed:
            self.log.info("Waiting for processing to complete before stopping writer.")
            time.sleep(1)

        self._is_running.clear()

        self._proc.join()
        # del self._proc

        self.log.info("Writer stopped. Avg write speed: %.2f MB/s", self.avg_write_speed_mb_s)

    def close(self) -> None:
        """Close the writer and clean up resources."""
        if self._is_running:
            self.stop()
        if self._dbl_buf:
            self._dbl_buf.close_and_unlink()
            del self._dbl_buf

    def _generate_ome_metadata(self) -> OME:
        """Generate OME metadata for the image stack using ome-types."""
        # Create Channel object
        channels = [
            Channel(
                id=f"Channel:0:{self.config.channel_idx}",
                name=self.config.channel_name,
                samples_per_pixel=1,
            ),
        ]

        # Create Pixels object
        pixels = Pixels(
            id="Pixels:0",
            dimension_order=self.dimension_order,
            type=self.pixel_type,
            size_x=int(self.config.frame_shape.x),
            size_y=int(self.config.frame_shape.y),
            size_z=self.config.frame_count,
            size_c=1,
            size_t=1,
            physical_size_x=self.config.voxel_size.x,
            physical_size_y=self.config.voxel_size.y,
            physical_size_z=self.config.voxel_size.z,
            physical_size_x_unit=self.voxel_size_unit,
            physical_size_y_unit=self.voxel_size_unit,
            physical_size_z_unit=self.voxel_size_unit,
            channels=channels,
        )

        # Create Image object
        image = Image(
            id="Image:0",
            name=self.config.file_name,
            pixels=pixels,
        )

        # Create OME object
        return OME(images=[image])
